{"id": "2506.19093", "pdf": "https://arxiv.org/pdf/2506.19093", "abs": "https://arxiv.org/abs/2506.19093", "authors": ["Fahmida Hai", "Shriya Samudrala", "Ijeoma Ezengwa", "Rubayat Khan", "Saif Nirzhor", "Don Roosan"], "title": "Harnessing Diet and Gene Expression Insights through a Centralized Nutrigenomics Database to Improve Public Health", "categories": ["q-bio.QM"], "comment": "Conference details can be found here:\n  https://www.insticc.org/node/technicalprogram/DATA/2025", "summary": "Nutrigenomics is an emerging field that explores the intricate interaction\nbetween genes and diet. This study aimed to develop a comprehensive database to\nhelp clinicians and patients understand the connections between genetic\ndisorders, associated genes, and tailored nutritional recommendations."}
{"id": "2506.19490", "pdf": "https://arxiv.org/pdf/2506.19490", "abs": "https://arxiv.org/abs/2506.19490", "authors": ["Neil Scheidwasser", "Ayush Nag", "Matthew J Penn", "Anthony MV Jakob", "Frederik M\u00f8lkj\u00e6r Andersen", "Mark P Khurana", "Landung Setiawan", "Madeline Gordon", "David A Duch\u00eane", "Samir Bhatt"], "title": "phylo2vec: a library for vector-based phylogenetic tree manipulation", "categories": ["q-bio.PE", "cs.DS"], "comment": "7 pages, 2 figures", "summary": "Phylogenetics is a fundamental component of many analysis frameworks in\nbiology as well as linguistics to study the evolutionary relationships of\ndifferent entities. Recently, the advent of large-scale genomics and the\nSARS-CoV-2 pandemic has underscored the necessity for phylogenetic software to\nhandle large datasets of genomes or phylogenetic trees. While significant\nefforts have focused on scaling optimisation algorithms, visualization, and\nlineage identification, an emerging body of research has been dedicated to\nefficient representations of data for genomes and phylogenetic trees such as\nphylo2vec. Compared to traditional tree representations such as the Newick\nformat, which represents trees using strings of nested parentheses, modern\nrepresentations of phylogenetic trees utilize integer vectors to define the\ntree topology traversal. This approach offers several advantages, including\neasier manipulability, increased memory efficiency, and applicability to\ndownstream tasks such as machine learning. Here, we present the latest release\nof phylo2vec (or Phylo2Vec), a high-performance software package for encoding,\nmanipulating, and analysing binary phylogenetic trees. At its core, the package\nis based on the phylo2vec representation of binary trees, which defines a\nbijection from any tree topology with $n$ leaves into an integer vector of size\n$n-1$. Compared to the traditional Newick format, phylo2vec is designed to\nenable fast sampling and comparison of binary trees. This release features a\ncore implementation in Rust, providing significant performance improvements and\nmemory efficiency, while remaining available in Python (superseding the release\ndescribed in the original paper) and R via dedicated wrappers, making it\naccessible to a broad audience in the bioinformatics community."}
{"id": "2506.19018", "pdf": "https://arxiv.org/pdf/2506.19018", "abs": "https://arxiv.org/abs/2506.19018", "authors": ["Ying-Jen Yang", "Charles D. Kocher", "Ken A. Dill"], "title": "Nonequilibrium Theory for Adaptive Systems in Varying Environments", "categories": ["cond-mat.stat-mech", "physics.bio-ph", "q-bio.PE"], "comment": null, "summary": "Biological organisms thrive by adapting to their environments, which are\noften unpredictably changeable. We apply recent results from nonequilibrium\nphysics to show that organisms' fitness parses into a static generalist\ncomponent and a nonequilibrium tracking component. Our findings: (1)\nEnvironmental changes that are too fast or too small are not worth tracking.\n(2) Well-timed anticipatory tracking enhances fitness in coherent environments.\n(3) We compute and explain the optimal adaptive strategy for a system in a\ngiven environment, such as bet hedging or phenotypic memory. Conversely, (4) We\ncompute and explain the optimal way for an environment to control a given\nsystem, for example for designing drug regimens to limit the growth of\npathogens. By connecting fitness, adaptive strategy, and environmental\nvariability, this work provides the foundations for a generic physical theory\nof adaptivity."}
{"id": "2506.19598", "pdf": "https://arxiv.org/pdf/2506.19598", "abs": "https://arxiv.org/abs/2506.19598", "authors": ["Alan N. Amin", "Andres Potapczynski", "Andrew Gordon Wilson"], "title": "Training Flexible Models of Genetic Variant Effects from Functional Annotations using Accelerated Linear Algebra", "categories": ["cs.LG", "q-bio.PE"], "comment": "For example: ICML 2025. Code available at:\n  https://github.com/AlanNawzadAmin/DeepWAS", "summary": "To understand how genetic variants in human genomes manifest in phenotypes --\ntraits like height or diseases like asthma -- geneticists have sequenced and\nmeasured hundreds of thousands of individuals. Geneticists use this data to\nbuild models that predict how a genetic variant impacts phenotype given genomic\nfeatures of the variant, like DNA accessibility or the presence of nearby\nDNA-bound proteins. As more data and features become available, one might\nexpect predictive models to improve. Unfortunately, training these models is\nbottlenecked by the need to solve expensive linear algebra problems because\nvariants in the genome are correlated with nearby variants, requiring inversion\nof large matrices. Previous methods have therefore been restricted to fitting\nsmall models, and fitting simplified summary statistics, rather than the full\nlikelihood of the statistical model. In this paper, we leverage modern fast\nlinear algebra techniques to develop DeepWAS (Deep genome Wide Association\nStudies), a method to train large and flexible neural network predictive models\nto optimize likelihood. Notably, we find that larger models only improve\nperformance when using our full likelihood approach; when trained by fitting\ntraditional summary statistics, larger models perform no better than small\nones. We find larger models trained on more features make better predictions,\npotentially improving disease predictions and therapeutic target\nidentification."}
